{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9gFWbzkIdNMi",
        "outputId": "58fe6b1e-f6a1-4aee-ac7e-267c0ce8fd9c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain_community in /usr/local/lib/python3.11/dist-packages (0.3.19)\n",
            "Collecting langchain_openai\n",
            "  Downloading langchain_openai-0.3.9-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.41 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.3.44)\n",
            "Requirement already satisfied: langchain<1.0.0,>=0.3.20 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.3.20)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.0.39)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (3.11.13)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (9.0.0)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.8.1)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.3.13)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.4.0)\n",
            "Requirement already satisfied: numpy<3,>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.0.2)\n",
            "Collecting langchain-core<1.0.0,>=0.3.41 (from langchain_community)\n",
            "  Downloading langchain_core-0.3.45-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting openai<2.0.0,>=1.66.3 (from langchain_openai)\n",
            "  Downloading openai-1.66.3-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting tiktoken<1,>=0.7 (from langchain_openai)\n",
            "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.18.3)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.6 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.20->langchain_community) (0.3.6)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.20->langchain_community) (2.10.6)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.41->langchain_community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.41->langchain_community) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.41->langchain_community) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (0.23.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.66.3->langchain_openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.66.3->langchain_openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.66.3->langchain_openai) (0.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.66.3->langchain_openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.66.3->langchain_openai) (4.67.1)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (1.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (2025.1.31)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.1.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.11.6)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.41->langchain_community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.20->langchain_community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.20->langchain_community) (2.27.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n",
            "Downloading langchain_openai-0.3.9-py3-none-any.whl (60 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.9/60.9 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.3.45-py3-none-any.whl (415 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m415.9/415.9 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openai-1.66.3-py3-none-any.whl (567 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m567.4/567.4 kB\u001b[0m \u001b[31m30.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m52.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tiktoken, openai, langchain-core, langchain_openai\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 1.61.1\n",
            "    Uninstalling openai-1.61.1:\n",
            "      Successfully uninstalled openai-1.61.1\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.44\n",
            "    Uninstalling langchain-core-0.3.44:\n",
            "      Successfully uninstalled langchain-core-0.3.44\n",
            "Successfully installed langchain-core-0.3.45 langchain_openai-0.3.9 openai-1.66.3 tiktoken-0.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain_community langchain_openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY"
      ],
      "metadata": {
        "id": "SneWj-LedghC"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Few Shot Prompting"
      ],
      "metadata": {
        "id": "KUQAAA8vBg2n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Use Case:**\n",
        "\n",
        "* When you need to provide the model with examples before asking for output."
      ],
      "metadata": {
        "id": "MPZwhFzkFHZY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**When to Use?**\n",
        "\n",
        "\n",
        "* When providing contextual learning to an AI model.\n",
        "\n",
        "* When you want the AI to follow a specific answering style."
      ],
      "metadata": {
        "id": "yfNZiCzvFOKR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import FewShotPromptTemplate, LLMChain, PromptTemplate\n",
        "from langchain_openai import OpenAI, ChatOpenAI"
      ],
      "metadata": {
        "id": "XkwCw7_s-xtd"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import FewShotPromptTemplate\n",
        "\n",
        "examples = [\n",
        "    {\"input\": \"What is AI?\", \"output\": \"AI stands for Artificial Intelligence.\"},\n",
        "    {\"input\": \"Explain ML.\", \"output\": \"ML stands for Machine Learning.\"}\n",
        "]\n",
        "\n",
        "example_template = PromptTemplate(\n",
        "    input_variables=[\"input\", \"output\"],\n",
        "    template=\"Q: {input}\\nA: {output}\"\n",
        ")\n",
        "\n",
        "few_shot_template = FewShotPromptTemplate(\n",
        "    examples=examples,\n",
        "    example_prompt=example_template,\n",
        "    prefix=\"I will answer the following questions:\",\n",
        "    suffix=\"Q: {query}\\nA:\",\n",
        "    input_variables=[\"query\"]\n",
        ")\n",
        "\n",
        "print(few_shot_template.format(query=\"What is NLP?\"))\n"
      ],
      "metadata": {
        "id": "6BRqzAoTeTtr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3fc6bb2-8fb1-4dcd-885c-959abeaae887"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I will answer the following questions:\n",
            "\n",
            "Q: What is AI?\n",
            "A: AI stands for Artificial Intelligence.\n",
            "\n",
            "Q: Explain ML.\n",
            "A: ML stands for Machine Learning.\n",
            "\n",
            "Q: What is NLP?\n",
            "A:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(few_shot_template.format(query=\"What is NLP?\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zvxVhyBZ_xWd",
        "outputId": "169a0983-0aab-4380-f807-0860fa3a9fc2"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I will answer the following questions:\n",
            "\n",
            "Q: What is AI?\n",
            "A: AI stands for Artificial Intelligence.\n",
            "\n",
            "Q: Explain ML.\n",
            "A: ML stands for Machine Learning.\n",
            "\n",
            "Q: What is NLP?\n",
            "A:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(few_shot_template.format(query='big'))"
      ],
      "metadata": {
        "id": "A5U-A3j9eXLD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4416ecbe-621d-49b7-fe28-793b569df73b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I will answer the following questions:\n",
            "\n",
            "Q: What is AI?\n",
            "A: AI stands for Artificial Intelligence.\n",
            "\n",
            "Q: Explain ML.\n",
            "A: ML stands for Machine Learning.\n",
            "\n",
            "Q: big\n",
            "A:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm = OpenAI(temperature=0)"
      ],
      "metadata": {
        "id": "qKUClkOqAj4u"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain=LLMChain(llm=llm,prompt=few_shot_template)"
      ],
      "metadata": {
        "id": "XeOP8A6YeZYr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6ac3528-886d-40fa-bfd2-bb2df8666b43"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-15-a06613d5a564>:1: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
            "  chain=LLMChain(llm=llm,prompt=few_shot_template)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain_output = chain({'query':\"big\"})"
      ],
      "metadata": {
        "id": "hqAHB2qxeblC"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(chain_output)"
      ],
      "metadata": {
        "id": "4bY44_kzefMi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a374149-1ee0-4107-f42b-c3aadaf09d3e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'query': 'big', 'text': ' Big is a word used to describe something that is large in size, quantity, or importance. It can also refer to something that is significant or influential.'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain_output1 = chain({'query':\"What is NLP?\"})"
      ],
      "metadata": {
        "id": "EVSe-V4aAvvH"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(chain_output1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZLg9ZC-tA4Vw",
        "outputId": "3db52045-7a62-474f-c14a-02ee38f362f5"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'query': 'What is NLP?', 'text': ' NLP stands for Natural Language Processing. It is a branch of AI that focuses on enabling computers to understand, interpret, and manipulate human language. This includes tasks such as speech recognition, language translation, and text analysis. NLP is used in various applications such as virtual assistants, chatbots, and sentiment analysis.'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(chain_output1['query'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "opau3OIqA9VY",
        "outputId": "3cf09afb-012e-4e7a-8fe0-e7520d7b0459"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What is NLP?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(chain_output1['text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rqmMufa1BJfA",
        "outputId": "5a064e8a-2150-4cb6-9a24-7d444ca5f297"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " NLP stands for Natural Language Processing. It is a branch of AI that focuses on enabling computers to understand, interpret, and manipulate human language. This includes tasks such as speech recognition, language translation, and text analysis. NLP is used in various applications such as virtual assistants, chatbots, and sentiment analysis.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Chain of Thought Prompt"
      ],
      "metadata": {
        "id": "jhQCfuu-BleI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Chain of Thought (CoT)** is a reasoning technique in generative AI where a model is encouraged to break down complex problems into intermediate steps before arriving at the final answer. This approach improves the model’s ability to handle multi-step reasoning tasks.\n",
        "\n",
        "In LangChain, CoT can be implemented in various ways using prompt engineering, function calling, and memory to ensure the model follows a structured reasoning path."
      ],
      "metadata": {
        "id": "9wYtX6D2C5l7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Use Cases of Chain of Thought in LangChain:**\n",
        "\n",
        "\n",
        "CoT reasoning is particularly useful in:\n",
        "\n",
        "* **Mathematical and Logical Reasoning**\n",
        "\n",
        " * Helps in solving step-by-step math problems, finance calculations, and logical puzzles.\n",
        "\n",
        "* **Question Answering and Conversational AI**\n",
        "\n",
        " * Enables better contextual understanding and memory for chatbots.\n",
        "\n",
        "* **Coding Assistance**\n",
        "\n",
        " * Debugging and code generation tasks that require structured reasoning.\n",
        "\n",
        "* **Finance and Data Analysis**\n",
        "\n",
        " * Used in AI models that analyze financial reports, stock trends, or automate investment strategies.\n",
        "\n",
        "* **Medical Diagnosis & Research**\n",
        "\n",
        " * Helps break down symptoms into logical steps for diagnosis.\n",
        "\n"
      ],
      "metadata": {
        "id": "0ssThugBDIIF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Chain of Thought Prompt\n",
        "prompt_template = PromptTemplate(\n",
        "    input_variables=[\"question\"],\n",
        "    template=\"\"\"You are a logical AI that follows a step-by-step reasoning process.\n",
        "\n",
        "    Question: {question}\n",
        "\n",
        "    Think step by step and provide the answer.\n",
        "    \"\"\"\n",
        ")"
      ],
      "metadata": {
        "id": "fNayZtUABsRz"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize LLM Model\n",
        "llm = ChatOpenAI(model_name=\"gpt-4\", temperature=0)"
      ],
      "metadata": {
        "id": "ML8Ee1BoB1JK"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create LLM Chain with CoT Prompt\n",
        "cot_chain = LLMChain(llm=llm, prompt=prompt_template)"
      ],
      "metadata": {
        "id": "iXa2_fvmB51K"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the Chain with a Sample Question\n",
        "question = \"If a train leaves at 8 AM and travels 60 miles per hour, how far will it travel by 11 AM?\""
      ],
      "metadata": {
        "id": "Qv7zWuN0B-CB"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cot_response = cot_chain.invoke(question)"
      ],
      "metadata": {
        "id": "S4EoAQ-ACDVa"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cot_response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bhaOn1MWCLcx",
        "outputId": "0f6b2f4b-031b-4a29-da2f-48dce1023ba9"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'question': 'If a train leaves at 8 AM and travels 60 miles per hour, how far will it travel by 11 AM?',\n",
              " 'text': \"Step 1: Determine the time duration of the train's travel. The train leaves at 8 AM and we want to know how far it will travel by 11 AM. So, the duration of the travel is 11 AM - 8 AM = 3 hours.\\n\\nStep 2: Use the formula for distance which is speed multiplied by time. The speed of the train is given as 60 miles per hour.\\n\\nStep 3: Multiply the speed of the train by the duration of the travel. So, 60 miles/hour * 3 hours = 180 miles.\\n\\nTherefore, the train will travel 180 miles by 11 AM.\"}"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cot_response['question']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "nPFzOsKFCO-p",
        "outputId": "09a9d958-7077-441e-e2a6-2b194051ca8b"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'If a train leaves at 8 AM and travels 60 miles per hour, how far will it travel by 11 AM?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cot_response['text']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "IiyS6tlVCSR5",
        "outputId": "7936ad2b-b14e-44ab-874f-94f97a03f04c"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Step 1: Determine the time duration of the train's travel. The train leaves at 8 AM and we want to know how far it will travel by 11 AM. So, the duration of the travel is 11 AM - 8 AM = 3 hours.\\n\\nStep 2: Use the formula for distance which is speed multiplied by time. The speed of the train is given as 60 miles per hour.\\n\\nStep 3: Multiply the speed of the train by the duration of the travel. So, 60 miles/hour * 3 hours = 180 miles.\\n\\nTherefore, the train will travel 180 miles by 11 AM.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(cot_response['text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90tLhnEXCWLS",
        "outputId": "fb6e425f-76a0-4aac-b89a-a7e7835bd22d"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 1: Determine the time duration of the train's travel. The train leaves at 8 AM and we want to know how far it will travel by 11 AM. So, the duration of the travel is 11 AM - 8 AM = 3 hours.\n",
            "\n",
            "Step 2: Use the formula for distance which is speed multiplied by time. The speed of the train is given as 60 miles per hour.\n",
            "\n",
            "Step 3: Multiply the speed of the train by the duration of the travel. So, 60 miles/hour * 3 hours = 180 miles.\n",
            "\n",
            "Therefore, the train will travel 180 miles by 11 AM.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##With Agent"
      ],
      "metadata": {
        "id": "yHpj7-x9EixG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import initialize_agent, AgentType\n",
        "from langchain.tools import Tool\n",
        "\n",
        "# Define a Tool to Perform Step-wise Calculation\n",
        "def simple_math_tool(question: str):\n",
        "    return f\"Step-by-step solution for: {question}\""
      ],
      "metadata": {
        "id": "_E_wMVNNEl-x"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "math_tool = Tool(\n",
        "    name=\"Math Solver\",\n",
        "    func=simple_math_tool,\n",
        "    description=\"Use this tool for multi-step math problems.\"\n",
        ")"
      ],
      "metadata": {
        "id": "1OUu67c8EscH"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize an OpenAI LLM\n",
        "llm = ChatOpenAI(model=\"gpt-4\", temperature=0)"
      ],
      "metadata": {
        "id": "ZawXRLW3Ewu4"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an Agent with CoT Reasoning\n",
        "agent = initialize_agent(\n",
        "    tools=[math_tool],\n",
        "    llm=llm,\n",
        "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
        "    verbose=True\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ERTQ0B1XE0PB",
        "outputId": "d872b7d3-21c0-4811-ef0c-9d6ba48d9457"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-37-f83b6e7806ee>:2: LangChainDeprecationWarning: LangChain agents will continue to be supported, but it is recommended for new use cases to be built with LangGraph. LangGraph offers a more flexible and full-featured framework for building agents, including support for tool-calling, persistence of state, and human-in-the-loop workflows. For details, refer to the `LangGraph documentation <https://langchain-ai.github.io/langgraph/>`_ as well as guides for `Migrating from AgentExecutor <https://python.langchain.com/docs/how_to/migrate_agent/>`_ and LangGraph's `Pre-built ReAct agent <https://langchain-ai.github.io/langgraph/how-tos/create-react-agent/>`_.\n",
            "  agent = initialize_agent(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the Agent with a Question\n",
        "response = agent.run(\"A car travels 45 mph for 2.5 hours. How far does it travel?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dzx1TYcbE3jm",
        "outputId": "2e538c21-56db-458c-d1cb-83b7ec55ec2e"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThis is a simple distance = speed * time problem.\n",
            "Action: Math Solver\n",
            "Action Input: 45 * 2.5\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mStep-by-step solution for: 45 * 2.5\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer.\n",
            "Final Answer: 112.5 miles\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_zaTF-zkE9Gw",
        "outputId": "eb8136b0-e94d-4d76-c5a1-04df5b6ef180"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "112.5 miles\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ReAct Prompt"
      ],
      "metadata": {
        "id": "1ILBeEOcGnMc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import OpenAI, ChatOpenAI\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.agents import initialize_agent, AgentType\n",
        "from langchain.tools import Tool\n",
        "from langchain.utilities import SerpAPIWrapper\n"
      ],
      "metadata": {
        "id": "f026QO8UGopD"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize OpenAI LLM\n",
        "llm = ChatOpenAI(model_name=\"gpt-4\", temperature=0)"
      ],
      "metadata": {
        "id": "gGvugBHKGuQU"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install google-search-results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2H9ChRrLH_Oe",
        "outputId": "af82ec04-80c7-42a8-c4e3-e889322fae8f"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting google-search-results\n",
            "  Downloading google_search_results-2.4.2.tar.gz (18 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from google-search-results) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->google-search-results) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->google-search-results) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->google-search-results) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->google-search-results) (2025.1.31)\n",
            "Building wheels for collected packages: google-search-results\n",
            "  Building wheel for google-search-results (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for google-search-results: filename=google_search_results-2.4.2-py3-none-any.whl size=32009 sha256=5152f168ccbc0a8782e3f3272e32863e11e9db950d194cac1442d35840db4d46\n",
            "  Stored in directory: /root/.cache/pip/wheels/6e/42/3e/aeb691b02cb7175ec70e2da04b5658d4739d2b41e5f73cd06f\n",
            "Successfully built google-search-results\n",
            "Installing collected packages: google-search-results\n",
            "Successfully installed google-search-results-2.4.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SERPER_API_KEY = userdata.get('SERPER_API_KEY')\n",
        "\n",
        "os.environ[\"SERPER_API_KEY\"] = SERPER_API_KEY"
      ],
      "metadata": {
        "id": "BCJprW4uHQNO"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a tool for web search (SerpAPI)\n",
        "search = SerpAPIWrapper(serpapi_api_key  = SERPER_API_KEY)\n",
        "search_tool = Tool(\n",
        "    name=\"Search\",\n",
        "    func=search.run,\n",
        "    description=\"Useful for retrieving current information from the web\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "Y87KMKhQG8t1"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize ReAct Agent\n",
        "react_agent = initialize_agent(\n",
        "    tools=[search_tool],\n",
        "    llm=llm,\n",
        "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
        "    verbose=True\n",
        ")"
      ],
      "metadata": {
        "id": "tXpKM1ndIHpf"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What is the latest news about AI?\""
      ],
      "metadata": {
        "id": "Y91dh7nGILk2"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = react_agent.run(query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mkfH9v1kIPd4",
        "outputId": "e8b6215e-8184-4380-e997-5ee14fce07e0"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mI need to search the web for the most recent news about AI.\n",
            "Action: Search\n",
            "Action Input: \"latest news about AI\"\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m[{'title': 'Trump again implies he is a King in sharing latest AI-generated meme', 'link': 'https://www.yahoo.com/news/trump-again-implies-king-sharing-162222560.html', 'source': 'Yahoo', 'date': '15 hours ago'}, {'title': \"Exclusive: Intel's new CEO plots overhaul of manufacturing and AI operations\", 'link': 'https://www.reuters.com/technology/intels-new-ceo-plots-overhaul-manufacturing-ai-operations-2025-03-17/', 'source': 'Reuters', 'date': '12 hours ago', 'thumbnail': 'https://serpapi.com/searches/67d91f36728439b772661e9e/images/86c588301748a5f668e8ad3edd4242106b94b36ecebbcc8f.jpeg'}, {'title': 'People are using Google’s new AI model to remove watermarks from images', 'link': 'https://techcrunch.com/2025/03/16/people-are-using-googles-new-ai-model-to-remove-watermarks-from-images/', 'source': 'TechCrunch', 'date': '1 day ago', 'thumbnail': 'https://serpapi.com/searches/67d91f36728439b772661e9e/images/86c588301748a5f6813589e02fa80b9f829b00ac9c0ad892.jpeg'}, {'title': 'How to use ChatGPT as a personal AI research assistant', 'link': 'https://www.popsci.com/diy/how-to-use-chatgpt-as-a-personal-ai-research-assistant/', 'source': 'Popular Science', 'date': '1 day ago', 'thumbnail': 'https://serpapi.com/searches/67d91f36728439b772661e9e/images/86c588301748a5f67729099396f72d6f3c9607fba096547a.jpeg'}]\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mI have found several recent news articles about AI. I can summarize these for the final answer.\n",
            "Final Answer: Here are some of the latest news about AI:\n",
            "1. \"Trump again implies he is a King in sharing latest AI-generated meme\" from Yahoo 15 hours ago. [Read more](https://www.yahoo.com/news/trump-again-implies-king-sharing-162222560.html)\n",
            "2. \"Exclusive: Intel's new CEO plots overhaul of manufacturing and AI operations\" from Reuters 12 hours ago. [Read more](https://www.reuters.com/technology/intels-new-ceo-plots-overhaul-manufacturing-ai-operations-2025-03-17/)\n",
            "3. \"People are using Google’s new AI model to remove watermarks from images\" from TechCrunch 1 day ago. [Read more](https://techcrunch.com/2025/03/16/people-are-using-googles-new-ai-model-to-remove-watermarks-from-images/)\n",
            "4. \"How to use ChatGPT as a personal AI research assistant\" from Popular Science 1 day ago. [Read more](https://www.popsci.com/diy/how-to-use-chatgpt-as-a-personal-ai-research-assistant/)\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "31WhNDR1ImfH",
        "outputId": "8f6d8869-8e0c-420c-ebac-8e308a72f44f"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here are some of the latest news about AI:\n",
            "1. \"Trump again implies he is a King in sharing latest AI-generated meme\" from Yahoo 15 hours ago. [Read more](https://www.yahoo.com/news/trump-again-implies-king-sharing-162222560.html)\n",
            "2. \"Exclusive: Intel's new CEO plots overhaul of manufacturing and AI operations\" from Reuters 12 hours ago. [Read more](https://www.reuters.com/technology/intels-new-ceo-plots-overhaul-manufacturing-ai-operations-2025-03-17/)\n",
            "3. \"People are using Google’s new AI model to remove watermarks from images\" from TechCrunch 1 day ago. [Read more](https://techcrunch.com/2025/03/16/people-are-using-googles-new-ai-model-to-remove-watermarks-from-images/)\n",
            "4. \"How to use ChatGPT as a personal AI research assistant\" from Popular Science 1 day ago. [Read more](https://www.popsci.com/diy/how-to-use-chatgpt-as-a-personal-ai-research-assistant/)\n"
          ]
        }
      ]
    }
  ]
}